import numpy as np
import cv2
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from keras.callbacks import EarlyStopping
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import os
import zipfile
from google.colab.patches import cv2_imshow  # For displaying images in Colab

# Image Classification function
def IC():
    epochs = 30  # Number of epochs for training
    categories = [
        'Tshirt', 'Shirt', 'Trouser', 'Jogger', 'Sweatshirt',
        'TankTop', 'BraletteTop', 'CamisoleTop', 'ChokerTop',
        'OffShoulderTop', 'Plazo', 'Skirt', 'WomenShort'
    ]  # Added 'Plazo', 'Skirt', 'WomenShort'
    cnt = 0
    path = "/content/drive/MyDrive/colgate7.zip"  # Path to the dataset zip file
    extract_dir = "/content/drive/MyDrive/colgate7"
    mix_dir = os.path.join(extract_dir, "mix")
    IMAGE_WIDTH = 30
    IMAGE_HEIGHT = 30
    IMAGE_CHANNELS = 3  # RGB images

    # Extract the dataset zip file if not already extracted
    if not os.path.exists(extract_dir):
        with zipfile.ZipFile(path, 'r') as zzip:
            zzip.extractall(extract_dir)

    # Ensure the 'mix' directory exists
    if not os.path.exists(mix_dir):
        os.makedirs(mix_dir)

    # Rename and prepare images in 'mix' directory
    for category in categories:
        category_dir = os.path.join(extract_dir, category)
        if os.path.exists(category_dir):
            for image_name in os.listdir(category_dir):
                cnt += 1
                image_path = os.path.join(category_dir, image_name)
                copypath = os.path.join(mix_dir, f"{category}.{cnt}.jpg")
                os.rename(image_path, copypath)
                print(f"Moved: {image_path} to {copypath}")
        else:
            print(f"Directory not found: {category_dir}")

    # Loading images using cv2
    input_data = []
    output_data = []
    unclassified_images = []
    for root, dirs, files in os.walk(mix_dir, topdown=False):
        for name in files:
            img_path = os.path.join(root, name)
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))
                input_data.append(img)
                category = name.split('.')[0]
                if category in categories:
                    output_data.append(categories.index(category))
                else:
                    unclassified_images.append(name)
                    os.remove(img_path)  # Remove unclassified image
            else:
                print(f"Error loading image: {img_path}")

    # Print unclassified images if any
    if unclassified_images:
        print(f"Removed unclassified images: {unclassified_images}")

    # Check for consistency in input and output data
    if len(input_data) != len(output_data):
        print(f"Inconsistent data: {len(input_data)} images, {len(output_data)} labels")
        return None, None, None

    inputs = np.asarray(input_data)
    outputs = np.asarray(output_data)

    # Splitting the dataset
    X_train, X_test, Y_train, Y_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)

    # Preprocessing the data
    X_train = X_train.astype('float32') / 255.0
    X_test = X_test.astype('float32') / 255.0

    Y_train = to_categorical(Y_train, num_classes=len(categories))
    Y_test = to_categorical(Y_test, num_classes=len(categories))

    # Building the model
    model = Sequential()
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(len(categories), activation='softmax'))

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # Training the model
    history = model.fit(X_train, Y_train, epochs=epochs, validation_data=(X_test, Y_test), callbacks=[EarlyStopping(patience=3)])

    return model, history, categories

# Preprocess image
def preprocess_image(img_path, target_size=(30, 30)):
    img = cv2.imread(img_path)
    if img is None:
        print(f"Error: Unable to read image from {img_path}")
        return None, None
    img_resized = cv2.resize(img, target_size)
    img_resized = img_resized.astype('float32') / 255.0
    return img, img_resized

# Predict image class
def predict_image_class(img, model, categories):
    img = np.expand_dims(img, axis=0)
    predictions = model.predict(img)
    predicted_class = np.argmax(predictions)
    print(f"Predicted Class: {categories[predicted_class]}")
    print(f"Class Probabilities: {predictions}")
    return predicted_class

# Draw bounding box
def draw_bounding_box(img, class_index, bbox_coords, categories):
    class_label = categories[class_index]
    color = (0, 255, 0)
    thickness = 2
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.5
    text_size, _ = cv2.getTextSize(class_label, font, font_scale, thickness)
    cv2.rectangle(img, (bbox_coords[0], bbox_coords[1]), (bbox_coords[2], bbox_coords[3]), color, thickness)
    cv2.rectangle(img, (bbox_coords[0], bbox_coords[1] - text_size[1]), (bbox_coords[0] + text_size[0], bbox_coords[1]), color, cv2.FILLED)
    cv2.putText(img, class_label, (bbox_coords[0], bbox_coords[1] - 5), font, font_scale, (0, 0, 0), thickness)
    return img

# Detect clothing and draw bounding box
def detect_clothing(image_path, model, categories):
    original_img, processed_img = preprocess_image(image_path)
    if original_img is None or processed_img is None:
        print("Error: Preprocessing failed.")
        return

    # Predict clothing class
    class_index = predict_image_class(processed_img, model, categories)

    # Define bounding box
    bbox_coords = (50, 50, 300, 300)

    result_img = draw_bounding_box(original_img.copy(), class_index, bbox_coords, categories)

    # Display the final image
    cv2_imshow(result_img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

# Train the model
trained_model, training_history, categories = IC()

if trained_model is not None:
    # Save the trained model
    trained_model.save('/content/drive/MyDrive/trained_model.h5')

    # Load the model for prediction
    model = load_model('/content/drive/MyDrive/trained_model.h5')

    # Example usage
    uploaded_image_path = '/content/skirts - 2025-01-24T110354.133.jpeg'  # Replace with your image path
    detect_clothing(uploaded_image_path, model, categories)